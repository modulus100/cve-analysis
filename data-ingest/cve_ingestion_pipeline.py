import datetime
import time
import requests
import psycopg2
import psycopg2.extras

# PostgreSQL connection details
db_config = {
    'dbname': 'cve',
    'user': 'cveuser',
    'password': 'cveuser-password',
    'host': 'localhost',
    'port': '5432'
}

batch_insert_size = 100
max_api_range_in_days = 120
days_to_fetch = 360
max_retries = 5
retry_backoff = 2  # in seconds
api_key = 'your_key'

# Establish a connection to the database
conn = psycopg2.connect(**db_config)
cursor = conn.cursor()

# Function to insert data into the products table
def get_or_create_product_ids(products):
    if not products:
        return {}

    product_ids = {}
    # Insert products in batch
    insert_query = '''
    INSERT INTO products (product_name, vendor_name)
    VALUES %s
    ON CONFLICT (product_name, vendor_name) DO NOTHING
    RETURNING id, product_name, vendor_name;
    '''
    psycopg2.extras.execute_values(
        cursor, insert_query, products, template=None, page_size=batch_insert_size
    )
    conn.commit()

    # Fetch the inserted product IDs
    select_query = '''
    SELECT id, product_name, vendor_name FROM products
    WHERE (product_name, vendor_name) IN %s;
    '''
    product_tuples = [(p[0], p[1]) for p in products]
    psycopg2.extras.execute_values(
        cursor, select_query, [product_tuples], template=None, page_size=batch_insert_size
    )
    result = cursor.fetchall()
    for row in result:
        product_ids[(row[1], row[2])] = row[0]
    return product_ids

# Function to insert data into the product_versions table
def insert_product_versions(product_versions):
    if not product_versions:
        return {}

    insert_query = '''
    INSERT INTO product_versions (product_id, version)
    VALUES %s
    ON CONFLICT DO NOTHING
    RETURNING id, product_id, version;
    '''
    psycopg2.extras.execute_values(
        cursor, insert_query, product_versions, template=None, page_size=batch_insert_size
    )
    conn.commit()

    # Fetch the inserted product version IDs
    select_query = '''
    SELECT id, product_id, version FROM product_versions
    WHERE (product_id, version) IN %s;
    '''
    version_tuples = [(p[0], p[1]) for p in product_versions]
    psycopg2.extras.execute_values(
        cursor, select_query, [version_tuples], template=None, page_size=batch_insert_size
    )
    result = cursor.fetchall()
    product_version_ids = {}
    for row in result:
        product_version_ids[(row[1], row[2])] = row[0]
    return product_version_ids

# Function to insert data into the vulnerabilities table
def insert_vulnerabilities(vulnerabilities):
    if not vulnerabilities:
        return []

    insert_query = '''
    INSERT INTO vulnerabilities (cve_id, description, published_date, last_modified_date)
    VALUES %s
    ON CONFLICT (cve_id) DO NOTHING
    RETURNING id, cve_id;
    '''
    psycopg2.extras.execute_values(
        cursor, insert_query, vulnerabilities, template=None, page_size=batch_insert_size
    )
    conn.commit()
    return cursor.fetchall()

# Function to insert data into the vulnerability_metrics table
def insert_vulnerability_metrics(metrics):
    if not metrics:
        return

    insert_query = '''
    INSERT INTO vulnerability_metrics (vulnerability_id, metric_name, metric_type, version, vector_string, attack_vector, attack_complexity, privileges_required, user_interaction, confidentiality_impact, integrity_impact, availability_impact, base_score, base_severity, exploitability_score, impact_score)
    VALUES %s
    ON CONFLICT (id) DO NOTHING;
    '''
    psycopg2.extras.execute_values(
        cursor, insert_query, metrics, template=None, page_size=batch_insert_size
    )
    conn.commit()

# Function to insert data into the product_vulnerabilities table
def insert_product_vulnerabilities(product_vulnerabilities):
    if not product_vulnerabilities:
        return

    insert_query = '''
    INSERT INTO product_vulnerabilities (product_version_id, vulnerability_id)
    VALUES %s
    ON CONFLICT (id) DO NOTHING;
    '''
    psycopg2.extras.execute_values(
        cursor, insert_query, product_vulnerabilities, template=None, page_size=batch_insert_size
    )
    conn.commit()

# Function to fetch and process CVE data
def fetch_and_process_cve_data(start_date, end_date):
    max_range = datetime.timedelta(days=max_api_range_in_days)
    current_start_date = start_date

    while current_start_date < end_date:
        print('Batch insert start for 120 days')
        current_end_date = min(current_start_date + max_range, end_date)
        
        # Format dates correctly for the NVD API
        start_date_str = current_start_date.strftime('%Y-%m-%dT%H:%M:%S')
        end_date_str = current_end_date.strftime('%Y-%m-%dT%H:%M:%S')
        headers = {'apiKey': api_key}
        
        # URL for the NVD API
        base_url = f"https://services.nvd.nist.gov/rest/json/cves/2.0/"
        url = f"{base_url}?pubStartDate={start_date_str}&pubEndDate={end_date_str}"
        
        N = 1
        while True:
            # Append pagination parameters if necessary
            paged_url = f"{url}&startIndex={(N - 1) * 2000}"  # Assuming each page contains 2000 results
            
            for attempt in range(max_retries):
                try:
                    response = requests.get(paged_url, timeout=10, headers=headers)
                    response.raise_for_status()
                    break
                except requests.exceptions.RequestException as e:
                    if attempt < max_retries - 1:
                        print(f"Request failed ({e}). Retrying in {retry_backoff} seconds...")
                        time.sleep(retry_backoff)
                        retry_backoff *= 2  # Exponential backoff
                    else:
                        print(f"Request failed after {max_retries} attempts: {e}")
                        return

            data = response.json()
            if 'totalResults' not in data or 'resultsPerPage' not in data or 'startIndex' not in data:
                print(f"Invalid response structure: {data}")
                break
            
            resultsPerPage = data['resultsPerPage']
            startIndex = data['startIndex']
            totalResults = data['totalResults']
            
            vulnerabilities = []
            metrics = []
            products = set()
            product_versions = set()
            product_vulnerabilities = []
            
            # Process each CVE item
            for item in data['vulnerabilities']:
                cve = item['cve']
                cve_id = cve['id']
                description = next((desc['value'] for desc in cve['descriptions'] if desc['lang'] == 'en'), '')
                published_date = cve['published'][:10]  # Extract date only (YYYY-MM-DD)
                last_modified_date = cve['lastModified'][:10]  # Extract date only (YYYY-MM-DD)
                
                vulnerabilities.append((cve_id, description, published_date, last_modified_date))
                
            # Perform batch insertion and fetch the generated IDs
            vulnerability_records = insert_vulnerabilities(vulnerabilities)
            vulnerability_dict = {cve_id: id for id, cve_id in vulnerability_records}
            
            # Process metrics and product vulnerabilities
            for item in data['vulnerabilities']:
                cve = item['cve']
                cve_id = cve['id']
                vulnerability_id = vulnerability_dict.get(cve_id)
                
                if not vulnerability_id:
                    continue
                
                for metric_name, metrics_list in cve.get('metrics', {}).items():
                    for metric in metrics_list:
                        cvss_data = metric.get('cvssData', {})
                        metrics.append((
                            vulnerability_id, metric_name, metric.get('type'), cvss_data.get('version'), 
                            cvss_data.get('vectorString'), cvss_data.get('attackVector'),
                            cvss_data.get('attackComplexity'), cvss_data.get('privilegesRequired'), 
                            cvss_data.get('userInteraction'), cvss_data.get('confidentialityImpact'), 
                            cvss_data.get('integrityImpact'), cvss_data.get('availabilityImpact'),
                            cvss_data.get('baseScore'), cvss_data.get('baseSeverity'), 
                            metric.get('exploitabilityScore'), metric.get('impactScore')
                        ))
                
                configurations = cve.get('configurations', [])
                for config in configurations:
                    for node in config['nodes']:
                        for cpe_match in node['cpeMatch']:
                            if cpe_match['vulnerable']:
                                cpe_parts = cpe_match['criteria'].split(':')
                                vendor_name = cpe_parts[3]
                                product_name = cpe_parts[4]
                                version = cpe_parts[5] if len(cpe_parts) > 5 else None
                                products.add((product_name, vendor_name))
                                product_versions.add((product_name, vendor_name, version, vulnerability_id))
            
            # Perform batch insertion for products and fetch their IDs
            product_ids = get_or_create_product_ids(list(products))
            
            # Prepare product versions with product IDs
            product_versions_to_insert = [(product_ids[(p[0], p[1])], p[2]) for p in product_versions]
            
            # Perform batch insertion for product versions and fetch their IDs
            product_version_ids = insert_product_versions(product_versions_to_insert)
            
            # Map product vulnerabilities to product version IDs
            product_vulnerabilities = [(product_version_ids[(product_ids[(p[0], p[1])], p[2])], p[3]) for p in product_versions]
            
            # Perform batch insertions
            if metrics:
                insert_vulnerability_metrics(metrics)
            if product_vulnerabilities:
                insert_product_vulnerabilities(product_vulnerabilities)
            
            # Check if we've retrieved all results
            if (startIndex + resultsPerPage) >= totalResults:
                break
            
            print(f"Processed page {N}")
            N += 1
        
        # Move to the next date range
        current_start_date = current_end_date + datetime.timedelta(days=1)
        print('Batch insert finish')

# Define the date range and fetch the data
print('Ingestion pipeline has started')
print("Total days:", days_to_fetch)
print(f"Batch Insert Size: {batch_insert_size}")
print(f"Max API Range in Days: {max_api_range_in_days}")
print(f"Days to Fetch: {days_to_fetch}")
print(f"Max Retries: {max_retries}")
print(f"Retry Backoff: {retry_backoff} seconds")
print(f"API Key: {api_key}")

end_date = datetime.datetime.now()
start_date = end_date - datetime.timedelta(days=days_to_fetch)
fetch_and_process_cve_data(start_date, end_date)

# Close the cursor and connection
cursor.close()
conn.close()
print('Ingestion pipeline is finished')
